{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "3b1bc55e31ec7e30dc690e47cd1308d3",
     "grade": false,
     "grade_id": "cell-c793b2b7fc5465d8",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "<b>Deadline:</b> March 20, 2024 (Wednesday) 23:00\n",
    "</div>\n",
    "\n",
    "# Exercise 2. Recommender system\n",
    "\n",
    "In this exercise, your task is to design a recommender system.\n",
    "\n",
    "## Learning goals:\n",
    "* Practise tuning a neural network model by using different regularization methods."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import tools\n",
    "import data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "skip_training = False  # Set this flag to True before validation and submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "97f36f0a997d795b2db131168549818c",
     "grade": true,
     "grade_id": "cell-281020e1f967884d",
     "locked": true,
     "points": 0,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# During evaluation, this cell sets skip_training to True\n",
    "# skip_training = True\n",
    "\n",
    "import tools, warnings\n",
    "warnings.showwarning = tools.customwarn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The data directory is data\n"
     ]
    }
   ],
   "source": [
    "# When running on your own computer, you can specify the data directory by:\n",
    "# data_dir = tools.select_data_dir('/your/local/data/directory')\n",
    "data_dir = tools.select_data_dir(\"data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select the device for training (use GPU if you have one)\n",
    "#device = torch.device('cuda:0')\n",
    "device = torch.device('cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "6dc2c53928c3ad25702c9ac906bc6ac3",
     "grade": false,
     "grade_id": "cell-799c694caf47e754",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "if skip_training:\n",
    "    # The models are always evaluated on CPU\n",
    "    device = torch.device(\"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "a83b3c898af9c33ba084f0dd0637ac8c",
     "grade": false,
     "grade_id": "cell-93b1b51f03178ceb",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## Ratings dataset\n",
    "\n",
    "We will train the recommender system on the dataset in which element consists of three values:\n",
    "* `user_id` - id of the user (the smallest user id is 1)\n",
    "* `item_id` - id of the item (the smallest item id is 1)\n",
    "* `rating` - rating given by the user to the item (ratings are integer numbers between 1 and 5).\n",
    "\n",
    "The recommender system need to predict the rating for any given pair of `user_id` and `item_id`.\n",
    "\n",
    "We measure the quality of the predicted ratings using the mean-squared error (MSE) loss:\n",
    "$$\n",
    "  \\frac{1}{N}\\sum_{i=1}^N (r_i - \\hat{r}_i)^2\n",
    "$$\n",
    "where $r_i$ is a real rating and $\\hat{r}_i$ is a predicted one.\n",
    "\n",
    "Note: The predicted rating $\\hat{r}_i$ does not have to be an integer number."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "49c9bb6f71c5bebac88f572ebc5fdf21",
     "grade": false,
     "grade_id": "cell-fb7ca3b718244670",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "trainset = data.RatingsData(root=data_dir, train=True)\n",
    "testset = data.RatingsData(root=data_dir, train=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "aa25e5e6256ec9dcb5dffe5b20d88f87",
     "grade": false,
     "grade_id": "cell-35493e186fda7a43",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "user_id=1, item_id=1, rating=5\n"
     ]
    }
   ],
   "source": [
    "# Print one sample from the dataset\n",
    "x = trainset[0]\n",
    "print(f'user_id={x[0]}, item_id={x[1]}, rating={x[2]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "6cab9939fbd855618ea15049c6584c91",
     "grade": false,
     "grade_id": "cell-40d7d3e85e395d42",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "# Model\n",
    "\n",
    "You need to design a recommender system model with the API described in the cell below.\n",
    "\n",
    "Hints on the model architecture:\n",
    "* You need to use [torch.nn.Embedding](https://pytorch.org/docs/stable/generated/torch.nn.Embedding.html?highlight=embedding#torch.nn.Embedding) layer to convert inputs `user_ids` and `item_ids` into reasonable representations. The idea of the embedding layer is that we want to represent similar users with values that are close to each other. The original representation as integers is not good for that. By using the embedding layer, we can learn such useful representations automatically.\n",
    "\n",
    "### Model tuning\n",
    "\n",
    "In this exercise, you need to tune the architecture of your model to achieve the best performance on the provided test set. You will notice that overfitting is a severe problem for this data: The model can easily overfit the training set producing poor accuracy on the out-of-training (test) data.\n",
    "\n",
    "You need to find an optimal combination of the hyperparameters, with some hyperparameters corresponding to the regularization techniques that we studied in the lecture.\n",
    "\n",
    "The hyperparameters that you are advised to consider:\n",
    "* Learning rate value and learning rate schedule (decresing the learning rate often has positive effect on the model performance)\n",
    "* Number of training epochs\n",
    "* Network size\n",
    "* Weight decay\n",
    "* Early stopping\n",
    "* Dropout\n",
    "* Increase amount of data:\n",
    "  * Data augmentation\n",
    "  * Injecting noise\n",
    "\n",
    "You can tune the hyperparameters by, for example, grid search, random search or manual tuning. In that case, you can use `architecture` argument to specify the hyperparameters that define the architecture of your network. After you have tuned the hyperparameters, set the default value of this argument to the optimal set of the hyparameters so that the best architecture is used in the accuracy tests.\n",
    "\n",
    "Note:\n",
    "* The number of points that you will get from this exercise depends on the MSE loss on the test set:\n",
    "  * below 1.00: 1 point\n",
    "  * below 0.95: 2 points\n",
    "  * below 0.92: 3 points\n",
    "  * below 0.90: 4 points\n",
    "  * below 0.89: 5 points\n",
    "  * below 0.88: 6 points "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "0e5876624dba2e059f4aea1c65d27dfa",
     "grade": false,
     "grade_id": "cell-c3cffbe259a08d4d",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "class RecommenderSystem(nn.Module):\n",
    "    def __init__(self, n_users, n_items,\n",
    "                 architecture=None  # If you want to tune the hyperparameters automatically (e.g. using random\n",
    "                                    # search), use this argument to specify the hyperparameters that define the\n",
    "                                    # architecture of your network. After you have tuned the hyperparameters,\n",
    "                                    # set the default value of this argument to the optimal set of the hyparameters\n",
    "                                    # so that the best architecture is used in the accuracy tests.\n",
    "                ):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "          n_users: Number of users.\n",
    "          n_items: Number of items.\n",
    "        \"\"\"\n",
    "        super(RecommenderSystem, self).__init__()\n",
    "        self.dim1 = 2\n",
    "        self.dim2 = 10\n",
    "        self.dim3 = 20\n",
    "        self.embedded1  = nn.Embedding(n_users, self.dim1)\n",
    "        self.embedded2  = nn.Embedding(n_items, self.dim1)\n",
    "        self.block      = nn.Sequential(\n",
    "            #nn.Linear(2 * self.dim1, self.dim2),\n",
    "            #nn.ReLU(),\n",
    "            #nn.Linear(self.dim2, self.dim3),\n",
    "            #nn.ReLU(),\n",
    "            #nn.Linear(self.dim3,1)\n",
    "            nn.Linear(2 * self.dim1, self.dim2),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(self.dim2,1)\n",
    "        )\n",
    "        \n",
    "        \n",
    "    def forward(self, user_ids, item_ids):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "          user_ids of shape (batch_size): User ids (starting from 1).\n",
    "          item_ids of shape (batch_size): Item ids (starting from 1).\n",
    "        \n",
    "        Returns:\n",
    "          outputs of shape (batch_size): Predictions of ratings.\n",
    "        \"\"\"\n",
    "        #print('User IDs shape:', user_ids.shape)\n",
    "        #print('Item IDs shape:', item_ids.shape)\n",
    "        #print('These should be the batchsize 5')\n",
    "        user_ids = self.embedded1(user_ids)\n",
    "        item_ids = self.embedded2(item_ids)\n",
    "        concat = torch.cat([user_ids, item_ids], dim=1)\n",
    "        \n",
    "        return self.block(concat).squeeze()\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "01bb09f330da9db46e6c8215cba93908",
     "grade": false,
     "grade_id": "cell-4963b96623072e67",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "You can test the shapes of the model outputs using the function below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "66e06523fac3af0ef33791d1f4b8b3d8",
     "grade": false,
     "grade_id": "cell-c6083c824af45d0c",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([10])\n",
      "Success\n"
     ]
    }
   ],
   "source": [
    "def test_RecommenderSystem_shapes():\n",
    "    n_users, n_items = 100, 1000\n",
    "    model = RecommenderSystem(n_users, n_items)\n",
    "    batch_size = 10\n",
    "    user_ids = torch.arange(1, batch_size+1)\n",
    "    item_ids = torch.arange(1, batch_size+1)\n",
    "    output = model(user_ids, item_ids)\n",
    "    print(output.shape)\n",
    "    assert output.shape == torch.Size([batch_size]), \"Wrong output shape.\"\n",
    "    print('Success')\n",
    "\n",
    "test_RecommenderSystem_shapes()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "450b5cbba95ea6ca97ff7d0c086abcc2",
     "grade": true,
     "grade_id": "cell-77bda8eb73762ef9",
     "locked": true,
     "points": 0,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# This cell is reserved for testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EarlyStopping:\n",
    "    def __init__(self, tolerance, patience):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "          patience (int):    Maximum number of epochs with unsuccessful updates.\n",
    "          tolerance (float): We assume that the update is unsuccessful if the validation error is larger\n",
    "                              than the best validation error so far plus this tolerance.\n",
    "        \"\"\"\n",
    "        self.tolerance = tolerance\n",
    "        self.patience = patience\n",
    "    \n",
    "    def stop_criterion(self, val_errors):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "          val_errors (iterable): Validation errors after every update during training.\n",
    "        \n",
    "        Returns: True if training should be stopped: when the validation error is larger than the best\n",
    "                  validation error obtained so far (with given tolearance) for patience epochs (number of consecutive epochs for which the criterion is satisfied).\n",
    "                 \n",
    "                 Otherwise, False.\n",
    "        \"\"\"\n",
    "        if len(val_errors) <= self.patience:\n",
    "            return False\n",
    "\n",
    "        min_val_error = min(val_errors)\n",
    "        val_errors = np.array(val_errors[-self.patience:])\n",
    "        return all(val_errors > min_val_error + self.tolerance)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "84fa4c2396a00177cefc9ae035b5ad1c",
     "grade": false,
     "grade_id": "cell-ba8b7cb0e60e0809",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## Train the model\n",
    "\n",
    "You need to train a recommender system using **only the training data.** Please use the test set to select the best model: the model that generalizes best to out-of-training data.\n",
    "\n",
    "**IMPORTANT**:\n",
    "* During testing, the predictions are produced by `predictions = model(user_ids, item_ids)` with the `user_ids` and `item_ids` loaded from `RatingsData`.\n",
    "* There is a size limit of 30Mb for saved models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "9de82b03bc4514fc2e9c8e71fe0eab6f",
     "grade": false,
     "grade_id": "cell-d149dfc0245469b4",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# Create the model\n",
    "# IMPORTANT: the default value of the architecture argument should define your best model.\n",
    "model = RecommenderSystem(trainset.n_users, trainset.n_items)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ID of current CUDA device: 0\n",
      "Name of current CUDA device: NVIDIA GeForce RTX 2080\n",
      "cpu\n"
     ]
    }
   ],
   "source": [
    "# Implement the training loop in this cell\n",
    "def to_device(data, device):\n",
    "    if isinstance(data, (list,tuple)):\n",
    "        return [to_device(x, device) for x in data]\n",
    "    return data.to(device)#, non_blocking=True)\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    # Storing ID of current CUDA device\n",
    "    cuda_id = torch.cuda.current_device()\n",
    "    print(f\"ID of current CUDA device: {torch.cuda.current_device()}\")\n",
    "        \n",
    "    print(f\"Name of current CUDA device: {torch.cuda.get_device_name(cuda_id)}\")\n",
    "\n",
    "    print(device.type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_accuracy(net, ids, items, labels):\n",
    "    net.eval()\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        outputs = net.forward(ids, items)\n",
    "        predicted = torch.round(outputs).long()\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "    return correct / total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_mse_loss(net, x, y, z):\n",
    "    net.eval()\n",
    "    mse_loss = nn.MSELoss()\n",
    "    total_loss = 0\n",
    "    total_samples = 0\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        #ids = to_device(x, device)\n",
    "        #items = to_device(y, device)\n",
    "        #labels = to_device(z, device)\n",
    "        ids = x\n",
    "        items = y\n",
    "        labels = z\n",
    "        \n",
    "        outputs = net.forward(ids, items)\n",
    "        loss = mse_loss(outputs, labels)\n",
    "        total_loss += loss.item() * labels.size(0)\n",
    "        total_samples += labels.size(0)\n",
    "        \n",
    "    return total_loss / total_samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is the function to print the progress during training\n",
    "def print_progress(epoch, train_error, val_error):\n",
    "    print('Epoch {}: Train error: {:.4f}, Test error: {:.4f}'.format(\n",
    "        epoch, train_error, val_error))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_noise(x, noise_std):\n",
    "    \"\"\"Add Gaussian noise to a PyTorch tensor.\n",
    "    \n",
    "    Args:\n",
    "      x (tensor): PyTorch tensor of inputs.\n",
    "      noise_std (float): Standard deviation of the Gaussian noise.\n",
    "      \n",
    "    Returns:\n",
    "      x: Tensor with Gaussian noise added.\n",
    "    \"\"\"\n",
    "    return x + noise_std * torch.randn(x.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "9ae611f86dc42c930a1421847d3310e8",
     "grade": false,
     "grade_id": "cell-d821843867334aed",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\n    for epoch in range(epochs):\\n        model.train()\\n        for batch in train_loader:\\n            optimizer.zero_grad()\\n            \\n            ids, items, labels = batch\\n            ids = to_device(torch.LongTensor(ids), device)\\n            items = to_device(torch.LongTensor(items), device)\\n            labels = to_device(torch.FloatTensor(labels.float()), device)\\n\\n            print('Datatype of ids: ', ids.dtype)\\n            print('Datatype of items: ', items.dtype)\\n            print('Datatype of labels: ', labels.dtype)\\n\\n            outputs = model.forward(ids, items)\\n            print('Outputs shape: ', outputs.dtype)\\n            loss = loss_fn(outputs, labels)\\n            loss.backward()\\n            optimizer.step()\\n            print('Epoch %d, loss = %.4f' % (epoch, loss.item()))\\n\\n            train_errors.append(compute_mse_loss(model, ids, items, outputs))\\n            val_errors.append(compute_mse_loss(model, ids_test, items_test, labels_test))\\n        if early_stop.stop_criterion(val_errors):\\n            print(val_errors[epoch])\\n            print('Stop after %d epochs' % epoch)\\n            break\\n\\n        if (epoch+1) % 100 == 0:\\n            print_progress(epoch, train_errors[epoch], val_errors[epoch])\\n\""
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Implement the training loop in this cell\n",
    "#model = RecommenderSystem(trainset.n_users, trainset.n_items)\n",
    "\n",
    "#print('Number of trainable parameters: ', sum(p.numel() for p in model.parameters() if p.requires_grad))\n",
    "\n",
    "# TODO: Increase the amount of data\n",
    "# Either by inserting noise or data augmentation\n",
    "\n",
    "\n",
    "# Learning rate value and learning rate schedule \n",
    "# (decresing the learning rate often has positive \n",
    "# effect on the model performance)\n",
    "# Number of training epochs\n",
    "# Network size\n",
    "# Weight decay\n",
    "# Early stopping\n",
    "# Dropout\n",
    "# Increase amount of data:\n",
    "  # Data augmentation\n",
    "  # Injecting noise\n",
    "\"\"\"\n",
    "if not skip_training:\n",
    "    #torch.cuda.empty_cache()\n",
    "    #memory_allocated = torch.cuda.memory_allocated()\n",
    "    #print(\"Memory allocated on GPU:\", memory_allocated * 1e-9, \"gigabytes\")\n",
    "\n",
    "    #memory_reserved = torch.cuda.memory_reserved()\n",
    "    #print(\"Memory reserved on GPU:\", memory_reserved * 1e-9, \"gigabytes\")\n",
    "\n",
    "    loss_fn = nn.MSELoss()\n",
    "    #optimizer = optim.Adam(model.parameters(), lr=0.0001)\n",
    "    optimizer = optim.SGD(model.parameters(), lr=0.0001, momentum=0.9, weight_decay=0.0001)\n",
    "    epochs = 2000\n",
    "    model.to(device)\n",
    "\n",
    "    train_errors = []  # Keep track of the training error\n",
    "    val_errors = []  # Keep track of the validation error\n",
    "    early_stop = EarlyStopping(tolerance=0.0001, patience=20)\n",
    "\n",
    "    #ids         = to_device(torch.LongTensor(trainset[0]), device)\n",
    "    #items       = to_device(torch.LongTensor(trainset[1]), device)\n",
    "    #labels      = to_device(torch.FloatTensor(trainset[2]), device)\n",
    "\n",
    "    \n",
    "\n",
    "    ids = []\n",
    "    items = []\n",
    "    labels = []\n",
    "\n",
    "    for sample in trainset:\n",
    "        ids.append(sample[0])\n",
    "        items.append(sample[1])\n",
    "        labels.append(sample[2])\n",
    "\n",
    "    ids_test = []\n",
    "    items_test = []\n",
    "    labels_test = []\n",
    "\n",
    "    for sample in testset:\n",
    "        ids_test.append(sample[0])\n",
    "        items_test.append(sample[1])\n",
    "        labels_test.append(sample[2])\n",
    "    \n",
    "\n",
    "\n",
    "    #ids         = to_device(torch.LongTensor(ids), device)\n",
    "    #items       = to_device(torch.LongTensor(items), device)\n",
    "    #labels      = to_device(torch.FloatTensor(labels), device)\n",
    "\n",
    "    #ids = torch.LongTensor(ids)\n",
    "    #items = torch.LongTensor(items)\n",
    "    #labels = torch.FloatTensor(labels)\n",
    "\n",
    "    #ids = to_device(ids, device)\n",
    "    #items = to_device(items, device)\n",
    "    #labels = to_device(labels, device)\n",
    "\n",
    "    #print('Ids device: ', ids.device)\n",
    "    #print('Items device: ', items.device)\n",
    "    #print('Labels device: ', labels.device)\n",
    "\n",
    "\n",
    "    #ids_test    = to_device(torch.LongTensor(ids_test), device)\n",
    "    #items_test  = to_device(torch.LongTensor(ids_test), device)\n",
    "    #labels_test = to_device(torch.FloatTensor(ids_test), device)\n",
    "\n",
    "    #ids_test = torch.LongTensor(ids_test)\n",
    "    #items_test = torch.LongTensor(items_test)\n",
    "    #labels_test = torch.FloatTensor(labels_test)\n",
    "\n",
    "    #ids_test = to_device(ids_test, device)\n",
    "    #items_test = to_device(items_test, device)\n",
    "    #labels_test = to_device(labels_test, device)\n",
    "\n",
    "\n",
    "    #print('Ids_test device: ', ids_test.device)\n",
    "    #print('Items_test device: ', items_test.device)\n",
    "    #print('Labels_test device: ', labels_test.device)\n",
    "\n",
    "    std1 = 0.5\n",
    "    std2 = 0.3\n",
    "\n",
    "    #ids_augmented   = torch.cuda.LongTensor((ids + to_device(torch.rand(ids.shape) * std1, device)).long())\n",
    "    #items_augmented = torch.cuda.LongTensor((items + to_device(torch.rand(items.shape) * std2, device)).long())\n",
    "    #labels = torch.cat([labels, labels], dim=0)\n",
    "\n",
    "    #ids = to_device(torch.cat([ids, ids_augmented]), device)\n",
    "    #items = to_device(torch.cat([items, items_augmented]), device)\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        #torch.cuda.empty_cache()\n",
    "        model.train()\n",
    "\n",
    "        memory_allocated = torch.cuda.memory_allocated()\n",
    "        print(\"Memory allocated on GPU on Epoch \", epoch, \":\", memory_allocated * 1e-9, \"gigabytes\")\n",
    "\n",
    "        for batch in train_loader:\n",
    "            optimizer.zero_grad()\n",
    "            ids, items, labels = batch\n",
    "\n",
    "            #ids = to_device(torch.LongTensor(ids), device)\n",
    "            #items = to_device(torch.LongTensor(items), device)\n",
    "            #labels = to_device(torch.FloatTensor(labels.float()), device)\n",
    "            \n",
    "            ids = torch.LongTensor(ids)\n",
    "            items = torch.LongTensor(items)\n",
    "            labels = torch.FloatTensor(labels.float())\n",
    "\n",
    "            ids = ids.to(device)\n",
    "            items = items.to(device)\n",
    "            labels = labels.to(device)\n",
    "\n",
    "            outputs = model.forward(ids, items)\n",
    "            loss = loss_fn(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            #train_errors.append(compute_mse_loss(model, ids, items, outputs))\n",
    "            train_errors.append(F.mse_loss(outputs, labels))\n",
    "\n",
    "        model.eval()\n",
    "        for batch in test_loader:\n",
    "            ids, items, labels = batch\n",
    "            ids = to_device(torch.LongTensor(ids), device)\n",
    "            items = to_device(torch.LongTensor(items), device)\n",
    "            labels = to_device(torch.FloatTensor(labels.float()), device)\n",
    "\n",
    "            outputs = model.forward(ids, items)\n",
    "            #val_errors.append(compute_mse_loss(model, ids, items, outputs))\n",
    "            val_errors.append(F.mse_loss(outputs, labels))\n",
    "\n",
    "        if early_stop.stop_criterion(val_errors):\n",
    "            print('Stop after %d epochs' % epoch)\n",
    "            break\n",
    "\n",
    "        if (epoch+1) % 100 == 0:\n",
    "            print_progress(epoch, train_errors[epoch], val_errors[epoch])\n",
    "    print('Finished Training')\n",
    "    #print('Test accuracy: ', compute_accuracy(model, testset))\n",
    "    #print('MSELoss for trainset: ', compute_mse_loss(model, ids, items, outputs))\n",
    "    #print('MSELoss for testset: ', compute_mse_loss(model, ids_test, items_test, labels_test))\n",
    "\"\"\"\n",
    "\n",
    "\"\"\"\n",
    "    for epoch in range(epochs):\n",
    "        model.train()\n",
    "        for batch in train_loader:\n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "            ids, items, labels = batch\n",
    "            ids = to_device(torch.LongTensor(ids), device)\n",
    "            items = to_device(torch.LongTensor(items), device)\n",
    "            labels = to_device(torch.FloatTensor(labels.float()), device)\n",
    "\n",
    "            print('Datatype of ids: ', ids.dtype)\n",
    "            print('Datatype of items: ', items.dtype)\n",
    "            print('Datatype of labels: ', labels.dtype)\n",
    "\n",
    "            outputs = model.forward(ids, items)\n",
    "            print('Outputs shape: ', outputs.dtype)\n",
    "            loss = loss_fn(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            print('Epoch %d, loss = %.4f' % (epoch, loss.item()))\n",
    "\n",
    "            train_errors.append(compute_mse_loss(model, ids, items, outputs))\n",
    "            val_errors.append(compute_mse_loss(model, ids_test, items_test, labels_test))\n",
    "        if early_stop.stop_criterion(val_errors):\n",
    "            print(val_errors[epoch])\n",
    "            print('Stop after %d epochs' % epoch)\n",
    "            break\n",
    "\n",
    "        if (epoch+1) % 100 == 0:\n",
    "            print_progress(epoch, train_errors[epoch], val_errors[epoch])\n",
    "\"\"\"\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "index out of range in self",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[76], line 115\u001b[0m\n\u001b[0;32m    110\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m batch_idx, (ids, items, labels) \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(train_loader):\n\u001b[0;32m    111\u001b[0m     \u001b[38;5;66;03m#print(ids, \"\\n\")\u001b[39;00m\n\u001b[0;32m    112\u001b[0m     \u001b[38;5;66;03m#print(items, \"\\n\")\u001b[39;00m\n\u001b[0;32m    114\u001b[0m     optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[1;32m--> 115\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mforward\u001b[49m\u001b[43m(\u001b[49m\u001b[43mids\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mitems\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    116\u001b[0m     \u001b[38;5;66;03m#print('Outputs shape: ', outputs.shape)\u001b[39;00m\n\u001b[0;32m    117\u001b[0m     \u001b[38;5;66;03m#print('Labels shape: ', labels.shape)\u001b[39;00m\n\u001b[0;32m    118\u001b[0m     loss \u001b[38;5;241m=\u001b[39m loss_fn(outputs, labels\u001b[38;5;241m.\u001b[39mfloat()\u001b[38;5;241m.\u001b[39msqueeze())\n",
      "Cell \u001b[1;32mIn[61], line 44\u001b[0m, in \u001b[0;36mRecommenderSystem.forward\u001b[1;34m(self, user_ids, item_ids)\u001b[0m\n\u001b[0;32m     33\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m     34\u001b[0m \u001b[38;5;124;03mArgs:\u001b[39;00m\n\u001b[0;32m     35\u001b[0m \u001b[38;5;124;03m  user_ids of shape (batch_size): User ids (starting from 1).\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     39\u001b[0m \u001b[38;5;124;03m  outputs of shape (batch_size): Predictions of ratings.\u001b[39;00m\n\u001b[0;32m     40\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m     41\u001b[0m \u001b[38;5;66;03m#print('User IDs shape:', user_ids.shape)\u001b[39;00m\n\u001b[0;32m     42\u001b[0m \u001b[38;5;66;03m#print('Item IDs shape:', item_ids.shape)\u001b[39;00m\n\u001b[0;32m     43\u001b[0m \u001b[38;5;66;03m#print('These should be the batchsize 5')\u001b[39;00m\n\u001b[1;32m---> 44\u001b[0m user_ids \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43membedded1\u001b[49m\u001b[43m(\u001b[49m\u001b[43muser_ids\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     45\u001b[0m item_ids \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39membedded2(item_ids)\n\u001b[0;32m     46\u001b[0m concat \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mcat([user_ids, item_ids], dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\Elias\\anaconda3\\envs\\DeepLearning\\lib\\site-packages\\torch\\nn\\modules\\module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\Elias\\anaconda3\\envs\\DeepLearning\\lib\\site-packages\\torch\\nn\\modules\\module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Elias\\anaconda3\\envs\\DeepLearning\\lib\\site-packages\\torch\\nn\\modules\\sparse.py:163\u001b[0m, in \u001b[0;36mEmbedding.forward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    162\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[1;32m--> 163\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43membedding\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    164\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpadding_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmax_norm\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    165\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnorm_type\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mscale_grad_by_freq\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msparse\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\Elias\\anaconda3\\envs\\DeepLearning\\lib\\site-packages\\torch\\nn\\functional.py:2237\u001b[0m, in \u001b[0;36membedding\u001b[1;34m(input, weight, padding_idx, max_norm, norm_type, scale_grad_by_freq, sparse)\u001b[0m\n\u001b[0;32m   2231\u001b[0m     \u001b[38;5;66;03m# Note [embedding_renorm set_grad_enabled]\u001b[39;00m\n\u001b[0;32m   2232\u001b[0m     \u001b[38;5;66;03m# XXX: equivalent to\u001b[39;00m\n\u001b[0;32m   2233\u001b[0m     \u001b[38;5;66;03m# with torch.no_grad():\u001b[39;00m\n\u001b[0;32m   2234\u001b[0m     \u001b[38;5;66;03m#   torch.embedding_renorm_\u001b[39;00m\n\u001b[0;32m   2235\u001b[0m     \u001b[38;5;66;03m# remove once script supports set_grad_enabled\u001b[39;00m\n\u001b[0;32m   2236\u001b[0m     _no_grad_embedding_renorm_(weight, \u001b[38;5;28minput\u001b[39m, max_norm, norm_type)\n\u001b[1;32m-> 2237\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43membedding\u001b[49m\u001b[43m(\u001b[49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpadding_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mscale_grad_by_freq\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msparse\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mIndexError\u001b[0m: index out of range in self"
     ]
    }
   ],
   "source": [
    "# Implement the training loop in this cell\n",
    "model = RecommenderSystem(trainset.n_users, trainset.n_items)\n",
    "\n",
    "#print('Number of trainable parameters: ', sum(p.numel() for p in model.parameters() if p.requires_grad))\n",
    "\n",
    "# TODO: Increase the amount of data\n",
    "# Either by inserting noise or data augmentation\n",
    "\n",
    "# Learning rate value and learning rate schedule \n",
    "# (decresing the learning rate often has positive \n",
    "# effect on the model performance)\n",
    "# Number of training epochs\n",
    "# Network size\n",
    "# Weight decay\n",
    "# Early stopping\n",
    "# Dropout\n",
    "# Increase amount of data:\n",
    "  # Data augmentation\n",
    "  # Injecting noise\n",
    "\n",
    "batch_size      = 10\n",
    "train_loader    = torch.utils.data.DataLoader(trainset  , batch_size=batch_size, shuffle=True)\n",
    "test_loader     = torch.utils.data.DataLoader(testset   , batch_size=batch_size, shuffle=False)\n",
    "\n",
    "if not skip_training:\n",
    "    loss_fn = nn.MSELoss()\n",
    "    optimizer = optim.SGD(model.parameters(), lr=0.0001, momentum=0.9, weight_decay=0.0001)\n",
    "    epochs = 2000\n",
    "    #model.to(device)\n",
    "\n",
    "    #train_errors = []  # Keep track of the training error\n",
    "    #val_errors = []  # Keep track of the validation error\n",
    "    #early_stop = EarlyStopping(tolerance=0.0001, patience=20)\n",
    "    \n",
    "    #ids = []\n",
    "    #items = []\n",
    "    #labels = []\n",
    "\n",
    "    #for sample in trainset:\n",
    "        #ids.append(sample[0])\n",
    "        #items.append(sample[1])\n",
    "        #labels.append(sample[2])\n",
    "    \n",
    "    #ids_test = []\n",
    "    #items_test = []\n",
    "    #labels_test = []\n",
    "\n",
    "    #for sample in testset:\n",
    "        #ids_test.append(sample[0])\n",
    "        #items_test.append(sample[1])\n",
    "        #labels_test.append(sample[2])\n",
    "    \n",
    "    #ids         = to_device(torch.LongTensor(ids), device)\n",
    "    #items       = to_device(torch.LongTensor(items), device)\n",
    "    #labels      = to_device(torch.FloatTensor(labels), device)\n",
    "    \n",
    "    #ids = torch.LongTensor(ids)\n",
    "    #items = torch.LongTensor(items)\n",
    "    #labels = torch.FloatTensor(labels)\n",
    "\n",
    "    #ids = to_device(ids, device)\n",
    "    #items = to_device(items, device)\n",
    "    #labels = to_device(labels, device)\n",
    "    \n",
    "    #unique_ids      = torch.unique(ids)\n",
    "    #unique_items    = torch.unique(items)\n",
    "\n",
    "    #print('Trainset n_users: ', trainset.n_users)\n",
    "    #print('Trainset n_items: ', trainset.n_items)\n",
    "\n",
    "    #print('Ids shape: ', ids.shape)\n",
    "    #print('Items shape: ', items.shape)\n",
    "    #print('Labels shape: ', labels.shape)\n",
    "\n",
    "    #print('Ids device: ', ids.device)\n",
    "    #print('Items device: ', items.device)\n",
    "    #print('Labels device: ', labels.device)\n",
    "\n",
    "    #ids_test    = to_device(torch.LongTensor(ids_test), device)\n",
    "    #items_test  = to_device(torch.LongTensor(ids_test), device)\n",
    "    #labels_test = to_device(torch.FloatTensor(ids_test), device)\n",
    "\n",
    "    #ids_test = torch.LongTensor(ids_test)\n",
    "    #items_test = torch.LongTensor(items_test)\n",
    "    #labels_test = torch.FloatTensor(labels_test)\n",
    "\n",
    "    #ids_test = to_device(ids_test, device)\n",
    "    #items_test = to_device(items_test, device)\n",
    "    #labels_test = to_device(labels_test, device)\n",
    "\n",
    "    #print('Ids_test device: ', ids_test.device)\n",
    "    #print('Items_test device: ', items_test.device)\n",
    "    #print('Labels_test device: ', labels_test.device)\n",
    "\n",
    "    std1 = 0.5\n",
    "    std2 = 0.3\n",
    "\n",
    "    #ids     = torch.arange(1, trainset.n_users+1)\n",
    "    #items   = torch.arange(1, trainset.n_items+1)\n",
    "\n",
    "    #ids_augmented   = torch.cuda.LongTensor((ids + to_device(torch.rand(ids.shape) * std1, device)).long())\n",
    "    #items_augmented = torch.cuda.LongTensor((items + to_device(torch.rand(items.shape) * std2, device)).long())\n",
    "    #labels = torch.cat([labels, labels], dim=0)\n",
    "\n",
    "    #ids = to_device(torch.cat([ids, ids_augmented]), device)\n",
    "    #items = to_device(torch.cat([items, items_augmented]), device)\n",
    "\n",
    "    for epoch in range(3):\n",
    "        #model.train()\n",
    "        for batch_idx, (ids, items, labels) in enumerate(train_loader):\n",
    "            #print(ids, \"\\n\")\n",
    "            #print(items, \"\\n\")\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model.forward(ids, items)\n",
    "            #print('Outputs shape: ', outputs.shape)\n",
    "            #print('Labels shape: ', labels.shape)\n",
    "            loss = loss_fn(outputs, labels.float().squeeze())\n",
    "            #print(loss)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "        #train_errors.append(F.mse_loss(outputs, labels))\n",
    "        \n",
    "        # Validation\n",
    "        #model.eval()\n",
    "        #outputs = model.forward(torch.unique(ids_test), torch.unique(items_test))\n",
    "        #val_errors.append(F.mse_loss(outputs, labels_test))\n",
    "\n",
    "        #if early_stop.stop_criterion(val_errors):\n",
    "            #print('Stop after %d epochs' % epoch)\n",
    "            #break\n",
    "\n",
    "        #if (epoch+1) % 100 == 0:\n",
    "            #print_progress(epoch, train_errors[epoch], val_errors[epoch])\n",
    "    print('Finished Training')\n",
    "    #print('Test accuracy: ', compute_accuracy(model, testset))\n",
    "    #print('MSELoss for trainset: ', compute_mse_loss(model, ids, items, outputs))\n",
    "    #print('MSELoss for testset: ', compute_mse_loss(model, ids_test, items_test, labels_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the model to disk (the pth-files will be submitted automatically together with your notebook)\n",
    "# Set confirm=False if you do not want to be asked for confirmation before saving.\n",
    "if not skip_training:\n",
    "    tools.save_model(model, 'recsys.pth', confirm=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "13f9cd9f77491dbdc099d1f0abb4ddbd",
     "grade": false,
     "grade_id": "cell-f1407ea48ef44720",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# This cell loads your best model\n",
    "if skip_training:\n",
    "    model = RecommenderSystem(trainset.n_users, trainset.n_items)\n",
    "    tools.load_model(model, 'recsys.pth', device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "f3a0c9a862742764c451006091c5295f",
     "grade": false,
     "grade_id": "cell-0968d93ce893a867",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "The next cell tests the accuracy of your best model. It is enough to submit .pth files.\n",
    "\n",
    "**IMPORTANT**:\n",
    "* During testing, the predictions are produced by `predictions = model(user_ids, item_ids)` with the `user_ids` and `item_ids` loaded from `RatingsData`.\n",
    "* There is a size limit of 30Mb for saved models. Please make sure that your model loads in the cell above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "d5da1ca794d9decc9969a31342685666",
     "grade": true,
     "grade_id": "cell-bffe8fbb471081d9",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# This cell tests the accuracy of your best model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "6424893302c13e465c2c75bbe70f8735",
     "grade": true,
     "grade_id": "cell-cd5e14d4b944f427",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# This cell is reserved for grading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "1c30f9763e61f52dedcc999c69901c79",
     "grade": true,
     "grade_id": "cell-d6d18ec22f375541",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# This cell is reserved for grading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "5bb64cc670252d78e6d0610fc87f818d",
     "grade": true,
     "grade_id": "cell-2a7cbd80cefdfc28",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# This cell is reserved for grading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "655de66b979f1ac0bc9009ef71201bee",
     "grade": true,
     "grade_id": "cell-583d64dae36d06ae",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# This cell is reserved for grading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "3df236f1b1d600d0ef716148cce58c46",
     "grade": true,
     "grade_id": "cell-545fe9918fc5b54a",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# This cell is reserved for grading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "845675607fd47b1ece1e7c5288e11561",
     "grade": true,
     "grade_id": "cell-a890dc0ffcb07f46",
     "locked": true,
     "points": 0,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# This cell is reserved for grading"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
